input {
	beats {
		port => 5044
	}

	tcp {
		port => 5000
	}

	kafka {
        bootstrap_servers => "192.168.199.193:9092,192.168.199.134:9092,192.168.199.133:9092" 
        group_id => "host_log"
        client_id => "logstash1" #注意，多台logstash实例消费同一个topics时，client_id需要指定不同的名字
        auto_offset_reset => "latest"
	    topics => ["pt.log"]
       	add_field => {"logs_type" => "pt.log"}
	    codec => json { charset => "UTF-8" }
	}
}

## Add your filters / logstash plugins configuration here

filter {
    grok {
        match => {
            "message" => "%{TIMESTAMP_ISO8601:logTime} %{GREEDYDATA:ptxId} %{GREEDYDATA:logThread} %{LOGLEVEL:logLevel} %{GREEDYDATA:logClass} %{GREEDYDATA:logContent}"
        }
    }
}

output {
	elasticsearch {
		hosts => "elasticsearch:9200"
		user => "elastic"
		password => "changeme"
		ecs_compatibility => disabled
	}
}
